{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Milestone 2: Feature Engineering, Baseline Model & Interpretability </center>\n",
    "\n",
    "### <center> Authors: Albina Cako & Joshua Dalphy </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [1. Getting Started](#1)\n",
    "* [2. Data Transformation](#2)\n",
    " * [2.1) Stemming the Dataset](#2.1)\n",
    " * [2.2) Removing Numerical Values](#2.2)\n",
    "* [3. Feature Extraction & Baseline Modelling](#3)\n",
    " * [3.1) Bag of Words - Count](#3.1)\n",
    " * [3.2) Bag of Words - TF-IDF](#3.2)\n",
    " * [3.3) Bag of Bi-Grams - Count](#3.3)\n",
    " * [3.4) Bag of Bi-Grams - TF-IDF](#3.3)\n",
    "* [4. Model Interpretation](#4)\n",
    " * [4.1) Confusion Matrices Comparison and Model Time Performance](#4.1)\n",
    " * [4.2) Feature Importance Using Decision Trees](#4.2)\n",
    "* [5. Conclusions](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting Started<a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "In this project we will be extracting features in our movie dataset using Bag of Words (count and TF-IDF methods) and Bag of Bi-Grams (count and TF-IDF methods). Logistic regression classification model was chosen as the baseline model to run the sentiment prediction. The best version of the feature extraction will be evaluated using confusion matrix and runtime of the logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>not understand comment focus mcconaughey never...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>let us say simple word even maker film may cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>year lose gorgeous jane parker maureen osulliv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews  Sentiments\n",
       "2932  not understand comment focus mcconaughey never...           1\n",
       "5537  let us say simple word even maker film may cha...           0\n",
       "1414  year lose gorgeous jane parker maureen osulliv...           1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import model_evaluation_utils as meu\n",
    "\n",
    "# Set print options\n",
    "np.set_printoptions(precision=2, linewidth=80)\n",
    "\n",
    "# Load the cleaned preprocessed dataset\n",
    "dataset = pd.read_csv('Movie_Reviews_Clean.csv')\n",
    "\n",
    "# Remove extra column\n",
    "dataset = dataset.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# replace positive with 1 and negative with 0\n",
    "dataset.Sentiments = dataset.Sentiments.replace('positive',1)\n",
    "dataset.Sentiments = dataset.Sentiments.replace('negative',0)\n",
    "\n",
    "dataset = shuffle(dataset)\n",
    "\n",
    "# Retrieve the reviews\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reivew and sentiment array\n",
    "reviews = np.array(dataset['Reviews'])\n",
    "sentiment = np.array(dataset['Sentiments'])\n",
    "\n",
    "# Split the reviews into testing and training 70/30\n",
    "index = round(0.7*len(reviews))\n",
    "\n",
    "train_reviews = reviews[:index]\n",
    "test_reviews  = reviews[index:]\n",
    "\n",
    "train_sentiments = sentiment[:index]\n",
    "test_sentiments  = sentiment[index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Transformation<a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Stemming the Dataset<a class=\"anchor\" id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the stemming function on train_reviews\n",
    "stem_train_reviews = [None]*len(train_reviews)\n",
    "idx = 0\n",
    "for sentence in train_reviews:\n",
    "    stem_train_reviews[idx] = stemSentence(sentence)\n",
    "    idx = idx + 1   \n",
    "\n",
    "# Apply the stemming function on test_reviews\n",
    "stem_test_reviews = [None]*len(test_reviews)\n",
    "idx = 0\n",
    "for sentence in test_reviews:\n",
    "    stem_test_reviews[idx] = stemSentence(sentence)\n",
    "    idx = idx + 1  \n",
    "\n",
    "    \n",
    "train_reviews = stem_train_reviews  \n",
    "test_reviews  = stem_test_reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Removing Numerical Values<a class=\"anchor\" id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove digits from a sentence\n",
    "import re\n",
    "def remove_digits(text):\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    #text = re.sub('[^a-zA-Z\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to train_reviews\n",
    "remove_digits_train = []\n",
    "for doc in train_reviews:\n",
    "    doc = remove_digits(doc)\n",
    "    remove_digits_train.append(doc)\n",
    "\n",
    "# Apply the function to test_reviews\n",
    "remove_digits_test = []\n",
    "for doc in test_reviews:\n",
    "    doc = remove_digits(doc)\n",
    "    remove_digits_test.append(doc)\n",
    "\n",
    "    \n",
    "train_reviews = remove_digits_train\n",
    "test_reviews = remove_digits_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Extraction & Baseline Modelling<a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Bag of Words - Count<a class=\"anchor\" id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1) Feature Extraction<a class=\"anchor\" id=\"3.1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build BOW features on train reviews\n",
    "BOW_cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,1))\n",
    "BOW_cv_train_features = BOW_cv.fit_transform(train_reviews)\n",
    "\n",
    "# transform test reviews into features\n",
    "BOW_cv_test_features = BOW_cv.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (4900, 24959)  Test features shape: (2100, 24959)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', BOW_cv_train_features.shape, ' Test features shape:', BOW_cv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adher',\n",
       " 'adhes',\n",
       " 'adibah',\n",
       " 'adieu',\n",
       " 'adio',\n",
       " 'aditiya',\n",
       " 'aditya',\n",
       " 'adject',\n",
       " 'adjoin',\n",
       " 'adjust',\n",
       " 'adkin',\n",
       " 'adler',\n",
       " 'administ',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admireranyon',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'admitedli',\n",
       " 'admitt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize some of the features\n",
    "bow_feature_names = BOW_cv.get_feature_names()\n",
    "bow_feature_names[200:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bernard</th>\n",
       "      <th>bernhard</th>\n",
       "      <th>berni</th>\n",
       "      <th>bernic</th>\n",
       "      <th>bernier</th>\n",
       "      <th>bernsen</th>\n",
       "      <th>bernstein</th>\n",
       "      <th>berri</th>\n",
       "      <th>berrisford</th>\n",
       "      <th>berryman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bernard  bernhard  berni  bernic  bernier  bernsen  bernstein  berri  \\\n",
       "0        0         0      0       0        0        0          0      0   \n",
       "1        0         0      0       0        0        0          0      0   \n",
       "2        0         0      0       0        0        0          0      0   \n",
       "\n",
       "   berrisford  berryman  \n",
       "0           0         0  \n",
       "1           0         0  \n",
       "2           0         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOW_matrix = BOW_cv_train_features.toarray()\n",
    "bow_df = pd.DataFrame(BOW_matrix, columns=bow_feature_names)\n",
    "bow_df.iloc[0:3,2000:2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2) Baseline Modelling - Logistic Regression<a class=\"anchor\" id=\"3.1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 851 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_bow_count = LogisticRegression(penalty='l2', max_iter=200, C=1)\n",
    "\n",
    "# Logistic Regression model on BOW-count features\n",
    "lr_bow_predictions = meu.train_predict_model(classifier=lr_bow_count, \n",
    "                                             train_features=BOW_cv_train_features, train_labels=train_sentiments,\n",
    "                                             test_features=BOW_cv_test_features, test_labels=test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8743\n",
      "Precision: 0.8747\n",
      "Recall: 0.8743\n",
      "F1 Score: 0.8743\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.89      0.87      1038\n",
      "           0       0.89      0.86      0.87      1062\n",
      "\n",
      "    accuracy                           0.87      2100\n",
      "   macro avg       0.87      0.87      0.87      2100\n",
      "weighted avg       0.87      0.87      0.87      2100\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "          Predicted:     \n",
      "                   1    0\n",
      "Actual: 1        922  116\n",
      "        0        148  914\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions,\n",
    "                                      classes=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Bag of Words - TF-IDF<a class=\"anchor\" id=\"3.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1) Feature Extraction<a class=\"anchor\" id=\"3.2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build TFIDF features on train reviews\n",
    "BOW_tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,1),\n",
    "                     sublinear_tf=True)\n",
    "BOW_tv_train_features = BOW_tv.fit_transform(train_reviews)\n",
    "\n",
    "# transform test reviews into features\n",
    "BOW_tv_test_features = BOW_tv.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF model:> Train features shape: (4900, 24959)  Test features shape: (2100, 24959)\n"
     ]
    }
   ],
   "source": [
    "print('TFIDF model:> Train features shape:', BOW_tv_train_features.shape, ' Test features shape:', BOW_tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bernard</th>\n",
       "      <th>bernhard</th>\n",
       "      <th>berni</th>\n",
       "      <th>bernic</th>\n",
       "      <th>bernier</th>\n",
       "      <th>bernsen</th>\n",
       "      <th>bernstein</th>\n",
       "      <th>berri</th>\n",
       "      <th>berrisford</th>\n",
       "      <th>berryman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bernard  bernhard  berni  bernic  bernier  bernsen  bernstein  berri  \\\n",
       "0      0.0       0.0    0.0     0.0      0.0      0.0        0.0    0.0   \n",
       "1      0.0       0.0    0.0     0.0      0.0      0.0        0.0    0.0   \n",
       "2      0.0       0.0    0.0     0.0      0.0      0.0        0.0    0.0   \n",
       "\n",
       "   berrisford  berryman  \n",
       "0         0.0       0.0  \n",
       "1         0.0       0.0  \n",
       "2         0.0       0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize some of the features\n",
    "bow_tv_feature_names = BOW_tv.get_feature_names()\n",
    "\n",
    "BOW_tv_matrix = BOW_tv_train_features.toarray()\n",
    "bow_tv_df = pd.DataFrame(BOW_tv_matrix, columns=bow_tv_feature_names)\n",
    "bow_tv_df.iloc[0:3,2000:2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2) Baseline Modelling - Logistic Regression<a class=\"anchor\" id=\"3.2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 293 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_bow_tfidf = LogisticRegression(penalty='l2', max_iter=200, C=1)\n",
    "\n",
    "# Logistic Regression model on BOW-TF-IDF features\n",
    "lr_bow_tfidf_predictions = meu.train_predict_model(classifier=lr_bow_tfidf, \n",
    "                                             train_features=BOW_tv_train_features, train_labels=train_sentiments,\n",
    "                                             test_features=BOW_tv_test_features, test_labels=test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8833\n",
      "Precision: 0.8839\n",
      "Recall: 0.8833\n",
      "F1 Score: 0.8833\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.90      0.88      1038\n",
      "           0       0.90      0.87      0.88      1062\n",
      "\n",
      "    accuracy                           0.88      2100\n",
      "   macro avg       0.88      0.88      0.88      2100\n",
      "weighted avg       0.88      0.88      0.88      2100\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "          Predicted:     \n",
      "                   1    0\n",
      "Actual: 1        935  103\n",
      "        0        142  920\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_tfidf_predictions,\n",
    "                                      classes=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Bag of Bi-Grams - Count<a class=\"anchor\" id=\"3.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1) Feature Extraction<a class=\"anchor\" id=\"3.2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build BOW features on train reviews\n",
    "BOBG_cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(2,2))\n",
    "BOBG_cv_train_features = BOBG_cv.fit_transform(train_reviews)\n",
    "\n",
    "# transform test reviews into features\n",
    "BOBG_cv_test_features = BOBG_cv.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOBG-count model:> Train features shape: (4900, 385586)  Test features shape: (2100, 385586)\n"
     ]
    }
   ],
   "source": [
    "print('BOBG-count model:> Train features shape:', BOBG_cv_train_features.shape, ' Test features shape:', BOBG_cv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abil endless',\n",
       " 'abil everi',\n",
       " 'abil expert',\n",
       " 'abil express',\n",
       " 'abil feel',\n",
       " 'abil figur',\n",
       " 'abil film',\n",
       " 'abil find',\n",
       " 'abil fine',\n",
       " 'abil full',\n",
       " 'abil give',\n",
       " 'abil good',\n",
       " 'abil help',\n",
       " 'abil hold',\n",
       " 'abil immedi',\n",
       " 'abil inflict',\n",
       " 'abil job',\n",
       " 'abil lie',\n",
       " 'abil like',\n",
       " 'abil limit']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize some of the features\n",
    "BOBG_feature_names = BOBG_cv.get_feature_names()\n",
    "BOBG_feature_names[200:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acid lay</th>\n",
       "      <th>acid morph</th>\n",
       "      <th>acid movi</th>\n",
       "      <th>acid mr</th>\n",
       "      <th>acid mushroom</th>\n",
       "      <th>acid never</th>\n",
       "      <th>acid poptart</th>\n",
       "      <th>acid quickli</th>\n",
       "      <th>acid seem</th>\n",
       "      <th>acid start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acid lay  acid morph  acid movi  acid mr  acid mushroom  acid never  \\\n",
       "0         0           0          0        0              0           0   \n",
       "1         0           0          0        0              0           0   \n",
       "2         0           0          0        0              0           0   \n",
       "\n",
       "   acid poptart  acid quickli  acid seem  acid start  \n",
       "0             0             0          0           0  \n",
       "1             0             0          0           0  \n",
       "2             0             0          0           0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOBG_matrix = BOBG_cv_train_features.toarray()\n",
    "bobg_df = pd.DataFrame(BOBG_matrix, columns=BOBG_feature_names)\n",
    "bobg_df.iloc[0:3,2000:2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2) Baseline Modelling - Logistic Regression<a class=\"anchor\" id=\"3.3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_bobg_count = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
    "\n",
    "# Logistic Regression model on BOBG-count features\n",
    "lr_bobg_count_predictions = meu.train_predict_model(classifier=lr_bobg_count, \n",
    "                                             train_features=BOBG_cv_train_features, train_labels=train_sentiments,\n",
    "                                             test_features=BOBG_cv_test_features, test_labels=test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8295\n",
      "Precision: 0.833\n",
      "Recall: 0.8295\n",
      "F1 Score: 0.8292\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.88      0.84      1038\n",
      "           0       0.87      0.78      0.82      1062\n",
      "\n",
      "    accuracy                           0.83      2100\n",
      "   macro avg       0.83      0.83      0.83      2100\n",
      "weighted avg       0.83      0.83      0.83      2100\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "          Predicted:     \n",
      "                   1    0\n",
      "Actual: 1        911  127\n",
      "        0        231  831\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bobg_count_predictions,classes=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4) Bag of Bi-Grams - TF-IDF<a class=\"anchor\" id=\"3.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1) Feature Extraction<a class=\"anchor\" id=\"3.4.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build TFIDF features on train reviews\n",
    "BOBG_tv_tfidf = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(2,2),\n",
    "                     sublinear_tf=True)\n",
    "BOBG_tv_tfidf_train_features = BOBG_tv_tfidf.fit_transform(train_reviews)\n",
    "\n",
    "# transform test reviews into features\n",
    "BOBG_tv_tfidf_test_features = BOBG_tv_tfidf.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOBG-tfidf model:> Train features shape: (4900, 385586)  Test features shape: (2100, 385586)\n"
     ]
    }
   ],
   "source": [
    "print('BOBG-tfidf model:> Train features shape:', BOBG_tv_tfidf_train_features.shape, ' Test features shape:', BOBG_tv_tfidf_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acid lay</th>\n",
       "      <th>acid morph</th>\n",
       "      <th>acid movi</th>\n",
       "      <th>acid mr</th>\n",
       "      <th>acid mushroom</th>\n",
       "      <th>acid never</th>\n",
       "      <th>acid poptart</th>\n",
       "      <th>acid quickli</th>\n",
       "      <th>acid seem</th>\n",
       "      <th>acid start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acid lay  acid morph  acid movi  acid mr  acid mushroom  acid never  \\\n",
       "0       0.0         0.0        0.0      0.0            0.0         0.0   \n",
       "1       0.0         0.0        0.0      0.0            0.0         0.0   \n",
       "2       0.0         0.0        0.0      0.0            0.0         0.0   \n",
       "\n",
       "   acid poptart  acid quickli  acid seem  acid start  \n",
       "0           0.0           0.0        0.0         0.0  \n",
       "1           0.0           0.0        0.0         0.0  \n",
       "2           0.0           0.0        0.0         0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize some of the features\n",
    "BOBG_tfidf_feature_names = BOBG_tv_tfidf.get_feature_names()\n",
    "\n",
    "BOBG_tfidf_matrix = BOBG_tv_tfidf_train_features.toarray()\n",
    "bobg_tfidf_df = pd.DataFrame(BOBG_tfidf_matrix, columns=BOBG_tfidf_feature_names)\n",
    "bobg_tfidf_df.iloc[0:3,2000:2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2) Baseline Modelling - Logistic Regression<a class=\"anchor\" id=\"3.4.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_bobg_tfidf = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
    "\n",
    "# Logistic Regression model on BOBG-count features\n",
    "lr_bobg_tfidf_predictions = meu.train_predict_model(classifier=lr_bobg_tfidf, \n",
    "                                             train_features=BOBG_tv_tfidf_train_features, train_labels=train_sentiments,\n",
    "                                             test_features=BOBG_tv_tfidf_test_features, test_labels=test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8295\n",
      "Precision: 0.833\n",
      "Recall: 0.8295\n",
      "F1 Score: 0.8292\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.88      0.84      1038\n",
      "           0       0.87      0.78      0.82      1062\n",
      "\n",
      "    accuracy                           0.83      2100\n",
      "   macro avg       0.83      0.83      0.83      2100\n",
      "weighted avg       0.83      0.83      0.83      2100\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "          Predicted:     \n",
      "                   1    0\n",
      "Actual: 1        911  127\n",
      "        0        231  831\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bobg_count_predictions,classes=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Interpretation<a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Confusion Matrices Comparison and Model Time Performance<a class=\"anchor\" id=\"4.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix was used to compare the 4 baseline models. Logistic regression was used as the baseline model for this milestone. \n",
    "\n",
    "### Bag of Words: Count vs. TF-IDF\n",
    "Looking at the confusion matrix, the model with the highest accuracy was the model where the features were extracted using Bag of Words - TF-IDF. Model trained with TF-IDF performed better then that with count, with a slightly higher accuracy of 1 %. The precision was also higher in both positive and negative sentiments. The TF-IDF model also had a lower false positive and false negative rate then the count method. However, both models showed a higher false positive rate, then false negative rate. \n",
    "\n",
    "Both logistic regression models ran quickly, 851 ms and 293 ms, for Count vs. TF-IDF respectively. However, the TF-IDF model ran about 3 times faster then the count model. For larger dataset, this model would be preferred due to faster run time. \n",
    "\n",
    "Overall, the TF-IDF trained model outperformed the count model. \n",
    "\n",
    "### Bag of Bi-Grams Count vs. TF-IDF\n",
    "Looking at the confusion matrix, both models that used feature extraction using Bag of N-Grams count and TF-IDF performed equally, with the exact same values in the confusion matrix. This shows that applying TF-IDF did not make a difference in feature extraction. \n",
    "\n",
    "The logistic regression model that was trained using count for feature extraction, ran slower then the model using TF-IDF, 3.08 s and 2.61 s, respectively. Thus, for performance time the TF-IDF model outperforms the Count Bag of Bi-Grams model. This model would have been chosen due to performance time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Feature Importance Using Random Forest<a class=\"anchor\" id=\"4.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library for decision trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Bag of Words - Count<a class=\"anchor\" id=\"4.1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a decision tree for feature selection\n",
    "bow_count_RF = RandomForestClassifier(n_estimators=100,random_state = 40)\n",
    "bow_count_RF = bow_count_RF.fit(BOW_cv_train_features,train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features are: 24959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bad       0.022325\n",
       "wast      0.009658\n",
       "great     0.009370\n",
       "not       0.007198\n",
       "love      0.006977\n",
       "beauti    0.005598\n",
       "bore      0.005547\n",
       "excel     0.005399\n",
       "aw        0.004676\n",
       "movi      0.004617\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp_bow_count = pd.Series(bow_count_RF.feature_importances_,index=bow_feature_names).sort_values(ascending=False)\n",
    "print(\"The number of features are:\",bow_count_RF.n_features_)\n",
    "feature_imp_bow_count[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Unimportant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features to remove are: 12955\n",
      "\n",
      "Display the first ten features that will be deleted:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aavjo',\n",
       " 'gangstermovi',\n",
       " 'aaja',\n",
       " 'gam',\n",
       " 'frutti',\n",
       " 'abet',\n",
       " 'entwistl',\n",
       " 'gard',\n",
       " 'frenchwoman',\n",
       " 'enrol']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_feature_remove = []\n",
    "for name in feature_imp_bow_count.index:\n",
    "    if feature_imp_bow_count[name] == 0:\n",
    "        bow_feature_remove.append(name)\n",
    "\n",
    "print(\"Number of features to remove are:\",len(bow_feature_remove))\n",
    "print(\"\\nDisplay the first ten features that will be deleted:\")\n",
    "bow_feature_remove[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Bag of Words - TF-IDF<a class=\"anchor\" id=\"4.1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a decision tree for feature selection\n",
    "bow_tfidf_RF = RandomForestClassifier(n_estimators=100,random_state = 40)\n",
    "bow_tfidf_RF = bow_count_RF.fit(BOW_tv_train_features,train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features are: 24959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bad       0.022325\n",
       "wast      0.009658\n",
       "great     0.009370\n",
       "not       0.007198\n",
       "love      0.006977\n",
       "beauti    0.005598\n",
       "bore      0.005547\n",
       "excel     0.005399\n",
       "aw        0.004676\n",
       "movi      0.004617\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp_bow_tfidf = pd.Series(bow_tfidf_RF.feature_importances_,index=bow_feature_names).sort_values(ascending=False)\n",
    "print(\"The number of features are:\",bow_tfidf_RF.n_features_)\n",
    "feature_imp_bow_tfidf[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Bag of Bi-Grams - Count<a class=\"anchor\" id=\"4.1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a decision tree for feature selection\n",
    "bobg_count_RF = RandomForestClassifier(n_estimators=100,random_state = 40)\n",
    "bobg_count_RF = bobg_count_RF.fit(BOBG_cv_train_features,train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features are: 385586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bad movi     0.009489\n",
       "not even     0.006314\n",
       "wast time    0.005406\n",
       "one bad      0.004259\n",
       "bad film     0.003904\n",
       "bad act      0.003404\n",
       "not wast     0.003240\n",
       "look like    0.002857\n",
       "movi bad     0.002468\n",
       "must see     0.002430\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp_bobg_count = pd.Series(bobg_count_RF.feature_importances_,index=BOBG_feature_names).sort_values(ascending=False)\n",
    "print(\"The number of features are:\",bobg_count_RF.n_features_)\n",
    "feature_imp_bobg_count[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Bag of Bi-Grams - TF-IDF<a class=\"anchor\" id=\"4.1.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a decision tree for feature selection\n",
    "bobg_tfidf_RF = RandomForestClassifier(n_estimators=100,random_state = 40)\n",
    "bobg_tfidf_RF = bobg_tfidf_RF.fit(BOBG_tv_tfidf_train_features ,train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features are: 385586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bad movi            0.009668\n",
       "not even            0.006154\n",
       "wast time           0.006069\n",
       "bad film            0.005183\n",
       "one bad             0.004875\n",
       "not wast            0.004077\n",
       "look like           0.003653\n",
       "movi bad            0.003521\n",
       "bad act             0.003065\n",
       "highli recommend    0.002675\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp_bobg_tfidf = pd.Series(bobg_tfidf_RF.feature_importances_,index=BOBG_feature_names).sort_values(ascending=False)\n",
    "print(\"The number of features are:\",bobg_tfidf_RF.n_features_)\n",
    "feature_imp_bobg_tfidf[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Unimportant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features to remove are: 300998\n",
      "\n",
      "Display the first ten features that will be deleted:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['franc dalen',\n",
       " 'armi get',\n",
       " 'franci matthew',\n",
       " 'art master',\n",
       " 'fortun get',\n",
       " 'franci may',\n",
       " 'franci drake',\n",
       " 'fulci bava',\n",
       " 'armi garrison',\n",
       " 'frasier make']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bobg_feature_remove = []\n",
    "for name in feature_imp_bobg_count.index:\n",
    "    if feature_imp_bobg_count[name] == 0:\n",
    "        bobg_feature_remove.append(name)\n",
    "\n",
    "print(\"Number of features to remove are:\",len(bobg_feature_remove))\n",
    "print(\"\\nDisplay the first ten features that will be deleted:\")\n",
    "bobg_feature_remove[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusions<a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Milestone 2 of the project, 4 models were ran by using Bag of Words (Count and TF-IDF) and Bag of Bi-Grams (Count and TF-IDF) for feature extraction. Logistic regression was chosen as the baseline model. Model performance was evaluated based on confusion matrix and runtime. The best performing model was using the features extracted through Bag of Words - TF-IDF. This model outperformed in confusion matrix metrics and in runtime. Random forest was used to identify important and unimportant features in the dataset. Exploration of these features is to be done in further milestones. \n",
    "\n",
    "The next step would be to tune the logistic regression model trained with features extracted from Bag of Words TF-IDF. The goal would be to get a higher model accuracy and improvement in all the confusion matrix parameters, especially reduction of false positive values, which was high in this model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
